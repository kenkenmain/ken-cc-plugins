# Phase 3.5: Test Review [PHASE 3.5]

## Subagent Config

- **Type:** kenken:codex-reviewer (uses codex-high MCP)
- **Input:** `.agents/tmp/kenken/phases/3.4-test-results.json`
- **Output:** `.agents/tmp/kenken/phases/3.5-test-review.json`

## Instructions

Review test quality using Codex MCP. Route through `kenken:codex-reviewer` agent.

### Process

1. Read test results from `.agents/tmp/kenken/phases/3.4-test-results.json`
2. Read test files that were written in Phase 3.2
3. Dispatch to Codex MCP (codex-high) with test review criteria
4. Write review result to output file

### Codex Dispatch

```
mcp__codex-high__codex(
  prompt: "Review test quality. Test results: .agents/tmp/kenken/phases/3.4-test-results.json. Test files: [list]. Return JSON with status, issues[], coverageAnalysis, summary.",
  cwd: "{project dir}"
)
```

### Review Criteria

**HIGH — tests that let bugs through:**

- Missing tests for critical functionality. The untested code path is the one that fails in production.
- Tests that always pass. No assertions = no test = bugs ship.
- Testing mocks instead of behavior. Verified the fake works, but the real code is still broken.
- Flaky tests. Random pass/fail. Team learns to ignore failures. Real failures get ignored.
- No error tests. If you don't test failure modes, you don't know what happens when things fail.

**MEDIUM — tests that probably let bugs through:**

- Missing edge cases. The edge case is the one that triggers the failure.
- Brittle tests. Break on refactor. Team disables them. Code path now untested.
- Duplicate coverage. Same test twice, critical path still untested.
- No boundary tests. Off by one. Wrong value passes validation.
- Loose assertions. `toBeTruthy` on a value that should be exactly `42`.

**LOW — tests that eventually let bugs through:**

- Poor naming. `test1` tests what? Nobody knows. Nobody maintains it.
- Bad organization. Can't find the test for a critical function.
- Redundant setup. Copy-paste test code becomes maintenance burden.

### Checklist

For each test file, verify:

- [ ] Happy path with realistic data
- [ ] Error conditions tested
- [ ] Boundaries tested (empty, null, max, min)
- [ ] Assertions verify behavior, not implementation
- [ ] Tests independent (no order dependency)
- [ ] Tests actually fail when code breaks

## Output Format

Write Codex response as JSON to `.agents/tmp/kenken/phases/3.5-test-review.json`:

```json
{
  "status": "approved" | "needs_revision",
  "issues": [
    {
      "severity": "HIGH" | "MEDIUM" | "LOW",
      "description": "...",
      "location": "test-file:line",
      "problem": "what bugs slip through",
      "fix": "how to prevent it"
    }
  ],
  "coverageAnalysis": {
    "criticalPathsCovered": ["..."],
    "criticalPathsMissing": ["..."]
  },
  "summary": "..."
}
```

### If Issues Found

If status is `needs_revision`:

1. Fix issues in test files
2. Re-run review (increment retryCount)
3. Repeat until approved or max retries

On max retries exceeded: ask user for guidance.

ANY HIGH issue = requires revision. Incomplete tests ship bugs.
